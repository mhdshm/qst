{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QST-CGAN For Reconstructing a Density matrix of Two-Entangled Photons\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-25 03:05:34.734195: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-25 03:05:34.908710: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-12-25 03:05:34.908744: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-12-25 03:05:35.948843: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-12-25 03:05:35.948962: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-12-25 03:05:35.948979: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#import friendly_traceback\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import qutip\n",
    "#os.execl(sys.executable, sys.executable, *sys.argv)\n",
    "#print(os.getcwd())\n",
    "# Add the path to the qst_cgan directory\n",
    "sys.path.append(os.path.abspath('/home/aq/qstgan/venv37/qst-cgan/'))\n",
    "from qutip import  Qobj\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#tf.config.run_functions_eagerly(True)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from qst_cgan.ops import convert_to_real_ops, tf_fidelity, dm_to_tf\n",
    "from qst_cgan.gan import generator_loss, discriminator_loss, Generator, Discriminator\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "%load_ext autoreload\n",
    "tf.keras.backend.set_floatx('float64') # Set float64 as the default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Measurement Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection number 1 (|H⟩⟨H|):\n",
      "[[1 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "Projection number 2 (|H⟩⟨R|):\n",
      "[[ 0.5+0.j   0. +0.5j  0. +0.j   0. +0.j ]\n",
      " [ 0. +0.5j -0.5+0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]]\n",
      "Projection number 3 (|H⟩⟨D|):\n",
      "[[0.5 0.5 0.  0. ]\n",
      " [0.5 0.5 0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]]\n",
      "Projection number 4 (|H⟩⟨L|):\n",
      "[[ 0.5+0.j   0. -0.5j  0. +0.j   0. +0.j ]\n",
      " [ 0. -0.5j -0.5+0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]]\n",
      "Projection number 5 (|H⟩⟨V|):\n",
      "[[0 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "Projection number 6 (|H⟩⟨A|):\n",
      "[[ 0.5 -0.5  0.   0. ]\n",
      " [-0.5  0.5  0.   0. ]\n",
      " [ 0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0. ]]\n",
      "Projection number 7 (|R⟩⟨A|):\n",
      "[[ 0.25+0.j   -0.25+0.j    0.  +0.25j  0.  -0.25j]\n",
      " [-0.25+0.j    0.25+0.j    0.  -0.25j  0.  +0.25j]\n",
      " [ 0.  +0.25j  0.  -0.25j -0.25+0.j    0.25+0.j  ]\n",
      " [ 0.  -0.25j  0.  +0.25j  0.25+0.j   -0.25+0.j  ]]\n",
      "Projection number 8 (|R⟩⟨V|):\n",
      "[[ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0.5+0.j   0. +0.j   0. +0.5j]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.5j  0. +0.j  -0.5+0.j ]]\n",
      "Projection number 9 (|R⟩⟨L|):\n",
      "[[ 0.25+0.j    0.  -0.25j  0.  +0.25j  0.25+0.j  ]\n",
      " [ 0.  -0.25j -0.25+0.j    0.25+0.j    0.  -0.25j]\n",
      " [ 0.  +0.25j  0.25+0.j   -0.25+0.j    0.  +0.25j]\n",
      " [ 0.25+0.j    0.  -0.25j  0.  +0.25j  0.25+0.j  ]]\n",
      "Projection number 10 (|R⟩⟨D|):\n",
      "[[ 0.25+0.j    0.25+0.j    0.  +0.25j  0.  +0.25j]\n",
      " [ 0.25+0.j    0.25+0.j    0.  +0.25j  0.  +0.25j]\n",
      " [ 0.  +0.25j  0.  +0.25j -0.25+0.j   -0.25+0.j  ]\n",
      " [ 0.  +0.25j  0.  +0.25j -0.25+0.j   -0.25+0.j  ]]\n",
      "Projection number 11 (|R⟩⟨R|):\n",
      "[[ 0.25+0.j    0.  +0.25j  0.  +0.25j -0.25+0.j  ]\n",
      " [ 0.  +0.25j -0.25+0.j   -0.25+0.j    0.  -0.25j]\n",
      " [ 0.  +0.25j -0.25+0.j   -0.25+0.j    0.  -0.25j]\n",
      " [-0.25+0.j    0.  -0.25j  0.  -0.25j  0.25+0.j  ]]\n",
      "Projection number 12 (|R⟩⟨H|):\n",
      "[[ 0.5+0.j   0. +0.j   0. +0.5j  0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.5j  0. +0.j  -0.5+0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]]\n",
      "Projection number 13 (|L⟩⟨H|):\n",
      "[[ 0.5+0.j   0. +0.j   0. -0.5j  0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. -0.5j  0. +0.j  -0.5+0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]]\n",
      "Projection number 14 (|L⟩⟨R|):\n",
      "[[ 0.25+0.j    0.  +0.25j  0.  -0.25j  0.25+0.j  ]\n",
      " [ 0.  +0.25j -0.25+0.j    0.25+0.j    0.  +0.25j]\n",
      " [ 0.  -0.25j  0.25+0.j   -0.25+0.j    0.  -0.25j]\n",
      " [ 0.25+0.j    0.  +0.25j  0.  -0.25j  0.25+0.j  ]]\n",
      "Projection number 15 (|L⟩⟨D|):\n",
      "[[ 0.25+0.j    0.25+0.j    0.  -0.25j  0.  -0.25j]\n",
      " [ 0.25+0.j    0.25+0.j    0.  -0.25j  0.  -0.25j]\n",
      " [ 0.  -0.25j  0.  -0.25j -0.25+0.j   -0.25+0.j  ]\n",
      " [ 0.  -0.25j  0.  -0.25j -0.25+0.j   -0.25+0.j  ]]\n",
      "Projection number 16 (|L⟩⟨L|):\n",
      "[[ 0.25+0.j    0.  -0.25j  0.  -0.25j -0.25+0.j  ]\n",
      " [ 0.  -0.25j -0.25+0.j   -0.25+0.j    0.  +0.25j]\n",
      " [ 0.  -0.25j -0.25+0.j   -0.25+0.j    0.  +0.25j]\n",
      " [-0.25+0.j    0.  +0.25j  0.  +0.25j  0.25+0.j  ]]\n",
      "Projection number 17 (|L⟩⟨V|):\n",
      "[[ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0.5+0.j   0. +0.j   0. -0.5j]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. -0.5j  0. +0.j  -0.5+0.j ]]\n",
      "Projection number 18 (|L⟩⟨A|):\n",
      "[[ 0.25+0.j   -0.25+0.j    0.  -0.25j  0.  +0.25j]\n",
      " [-0.25+0.j    0.25+0.j    0.  +0.25j  0.  -0.25j]\n",
      " [ 0.  -0.25j  0.  +0.25j -0.25+0.j    0.25+0.j  ]\n",
      " [ 0.  +0.25j  0.  -0.25j  0.25+0.j   -0.25+0.j  ]]\n",
      "Projection number 19 (|D⟩⟨A|):\n",
      "[[ 0.25 -0.25  0.25 -0.25]\n",
      " [-0.25  0.25 -0.25  0.25]\n",
      " [ 0.25 -0.25  0.25 -0.25]\n",
      " [-0.25  0.25 -0.25  0.25]]\n",
      "Projection number 20 (|D⟩⟨V|):\n",
      "[[0.  0.  0.  0. ]\n",
      " [0.  0.5 0.  0.5]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.5 0.  0.5]]\n",
      "Projection number 21 (|D⟩⟨L|):\n",
      "[[ 0.25+0.j    0.  -0.25j  0.25+0.j    0.  -0.25j]\n",
      " [ 0.  -0.25j -0.25+0.j    0.  -0.25j -0.25+0.j  ]\n",
      " [ 0.25+0.j    0.  -0.25j  0.25+0.j    0.  -0.25j]\n",
      " [ 0.  -0.25j -0.25+0.j    0.  -0.25j -0.25+0.j  ]]\n",
      "Projection number 22 (|D⟩⟨D|):\n",
      "[[0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]]\n",
      "Projection number 23 (|D⟩⟨R|):\n",
      "[[ 0.25+0.j    0.  +0.25j  0.25+0.j    0.  +0.25j]\n",
      " [ 0.  +0.25j -0.25+0.j    0.  +0.25j -0.25+0.j  ]\n",
      " [ 0.25+0.j    0.  +0.25j  0.25+0.j    0.  +0.25j]\n",
      " [ 0.  +0.25j -0.25+0.j    0.  +0.25j -0.25+0.j  ]]\n",
      "Projection number 24 (|D⟩⟨H|):\n",
      "[[0.5 0.  0.5 0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.5 0.  0.5 0. ]\n",
      " [0.  0.  0.  0. ]]\n",
      "Projection number 25 (|V⟩⟨H|):\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 0]]\n",
      "Projection number 26 (|V⟩⟨R|):\n",
      "[[ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0.5+0.j   0. +0.5j]\n",
      " [ 0. +0.j   0. +0.j   0. +0.5j -0.5+0.j ]]\n",
      "Projection number 27 (|V⟩⟨D|):\n",
      "[[0.  0.  0.  0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.5 0.5]\n",
      " [0.  0.  0.5 0.5]]\n",
      "Projection number 28 (|V⟩⟨L|):\n",
      "[[ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0.5+0.j   0. -0.5j]\n",
      " [ 0. +0.j   0. +0.j   0. -0.5j -0.5+0.j ]]\n",
      "Projection number 29 (|V⟩⟨V|):\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 1]]\n",
      "Projection number 30 (|V⟩⟨A|):\n",
      "[[ 0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.   0. ]\n",
      " [ 0.   0.   0.5 -0.5]\n",
      " [ 0.   0.  -0.5  0.5]]\n",
      "Projection number 31 (|A⟩⟨A|):\n",
      "[[ 0.25 -0.25 -0.25  0.25]\n",
      " [-0.25  0.25  0.25 -0.25]\n",
      " [-0.25  0.25  0.25 -0.25]\n",
      " [ 0.25 -0.25 -0.25  0.25]]\n",
      "Projection number 32 (|A⟩⟨V|):\n",
      "[[ 0.   0.   0.   0. ]\n",
      " [ 0.   0.5  0.  -0.5]\n",
      " [ 0.   0.   0.   0. ]\n",
      " [ 0.  -0.5  0.   0.5]]\n",
      "Projection number 33 (|A⟩⟨L|):\n",
      "[[ 0.25+0.j    0.  -0.25j -0.25+0.j    0.  +0.25j]\n",
      " [ 0.  -0.25j -0.25+0.j    0.  +0.25j  0.25+0.j  ]\n",
      " [-0.25+0.j    0.  +0.25j  0.25+0.j    0.  -0.25j]\n",
      " [ 0.  +0.25j  0.25+0.j    0.  -0.25j -0.25+0.j  ]]\n",
      "Projection number 34 (|A⟩⟨D|):\n",
      "[[ 0.25  0.25 -0.25 -0.25]\n",
      " [ 0.25  0.25 -0.25 -0.25]\n",
      " [-0.25 -0.25  0.25  0.25]\n",
      " [-0.25 -0.25  0.25  0.25]]\n",
      "Projection number 35 (|A⟩⟨R|):\n",
      "[[ 0.25+0.j    0.  +0.25j -0.25+0.j    0.  -0.25j]\n",
      " [ 0.  +0.25j -0.25+0.j    0.  -0.25j  0.25+0.j  ]\n",
      " [-0.25+0.j    0.  -0.25j  0.25+0.j    0.  +0.25j]\n",
      " [ 0.  -0.25j  0.25+0.j    0.  +0.25j -0.25+0.j  ]]\n",
      "Projection number 36 (|A⟩⟨H|):\n",
      "[[ 0.5  0.  -0.5  0. ]\n",
      " [ 0.   0.   0.   0. ]\n",
      " [-0.5  0.   0.5  0. ]\n",
      " [ 0.   0.   0.   0. ]]\n",
      "\n",
      "Saved projection matrices in 'opers':\n",
      "Matrix 1:\n",
      "[[1.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      " [0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      " [0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      " [0.+0.j 0.+0.j 0.+0.j 0.+0.j]]\n",
      "\n",
      "Matrix 2:\n",
      "[[ 0.5+0.j   0. +0.5j  0. +0.j   0. +0.j ]\n",
      " [ 0. +0.5j -0.5+0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]]\n",
      "\n",
      "Matrix 3:\n",
      "[[0.5+0.j 0.5+0.j 0. +0.j 0. +0.j]\n",
      " [0.5+0.j 0.5+0.j 0. +0.j 0. +0.j]\n",
      " [0. +0.j 0. +0.j 0. +0.j 0. +0.j]\n",
      " [0. +0.j 0. +0.j 0. +0.j 0. +0.j]]\n",
      "\n",
      "Matrix 4:\n",
      "[[ 0.5+0.j   0. -0.5j  0. +0.j   0. +0.j ]\n",
      " [ 0. -0.5j -0.5+0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]]\n",
      "\n",
      "Matrix 5:\n",
      "[[0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      " [0.+0.j 1.+0.j 0.+0.j 0.+0.j]\n",
      " [0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      " [0.+0.j 0.+0.j 0.+0.j 0.+0.j]]\n",
      "\n",
      "Matrix 6:\n",
      "[[ 0.5+0.j -0.5+0.j  0. +0.j  0. +0.j]\n",
      " [-0.5+0.j  0.5+0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j]]\n",
      "\n",
      "Matrix 7:\n",
      "[[ 0.25+0.j   -0.25+0.j    0.  +0.25j  0.  -0.25j]\n",
      " [-0.25+0.j    0.25+0.j    0.  -0.25j  0.  +0.25j]\n",
      " [ 0.  +0.25j  0.  -0.25j -0.25+0.j    0.25+0.j  ]\n",
      " [ 0.  -0.25j  0.  +0.25j  0.25+0.j   -0.25+0.j  ]]\n",
      "\n",
      "Matrix 8:\n",
      "[[ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0.5+0.j   0. +0.j   0. +0.5j]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.5j  0. +0.j  -0.5+0.j ]]\n",
      "\n",
      "Matrix 9:\n",
      "[[ 0.25+0.j    0.  -0.25j  0.  +0.25j  0.25+0.j  ]\n",
      " [ 0.  -0.25j -0.25+0.j    0.25+0.j    0.  -0.25j]\n",
      " [ 0.  +0.25j  0.25+0.j   -0.25+0.j    0.  +0.25j]\n",
      " [ 0.25+0.j    0.  -0.25j  0.  +0.25j  0.25+0.j  ]]\n",
      "\n",
      "Matrix 10:\n",
      "[[ 0.25+0.j    0.25+0.j    0.  +0.25j  0.  +0.25j]\n",
      " [ 0.25+0.j    0.25+0.j    0.  +0.25j  0.  +0.25j]\n",
      " [ 0.  +0.25j  0.  +0.25j -0.25+0.j   -0.25+0.j  ]\n",
      " [ 0.  +0.25j  0.  +0.25j -0.25+0.j   -0.25+0.j  ]]\n",
      "\n",
      "Matrix 11:\n",
      "[[ 0.25+0.j    0.  +0.25j  0.  +0.25j -0.25+0.j  ]\n",
      " [ 0.  +0.25j -0.25+0.j   -0.25+0.j    0.  -0.25j]\n",
      " [ 0.  +0.25j -0.25+0.j   -0.25+0.j    0.  -0.25j]\n",
      " [-0.25+0.j    0.  -0.25j  0.  -0.25j  0.25+0.j  ]]\n",
      "\n",
      "Matrix 12:\n",
      "[[ 0.5+0.j   0. +0.j   0. +0.5j  0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.5j  0. +0.j  -0.5+0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]]\n",
      "\n",
      "Matrix 13:\n",
      "[[ 0.5+0.j   0. +0.j   0. -0.5j  0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. -0.5j  0. +0.j  -0.5+0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]]\n",
      "\n",
      "Matrix 14:\n",
      "[[ 0.25+0.j    0.  +0.25j  0.  -0.25j  0.25+0.j  ]\n",
      " [ 0.  +0.25j -0.25+0.j    0.25+0.j    0.  +0.25j]\n",
      " [ 0.  -0.25j  0.25+0.j   -0.25+0.j    0.  -0.25j]\n",
      " [ 0.25+0.j    0.  +0.25j  0.  -0.25j  0.25+0.j  ]]\n",
      "\n",
      "Matrix 15:\n",
      "[[ 0.25+0.j    0.25+0.j    0.  -0.25j  0.  -0.25j]\n",
      " [ 0.25+0.j    0.25+0.j    0.  -0.25j  0.  -0.25j]\n",
      " [ 0.  -0.25j  0.  -0.25j -0.25+0.j   -0.25+0.j  ]\n",
      " [ 0.  -0.25j  0.  -0.25j -0.25+0.j   -0.25+0.j  ]]\n",
      "\n",
      "Matrix 16:\n",
      "[[ 0.25+0.j    0.  -0.25j  0.  -0.25j -0.25+0.j  ]\n",
      " [ 0.  -0.25j -0.25+0.j   -0.25+0.j    0.  +0.25j]\n",
      " [ 0.  -0.25j -0.25+0.j   -0.25+0.j    0.  +0.25j]\n",
      " [-0.25+0.j    0.  +0.25j  0.  +0.25j  0.25+0.j  ]]\n",
      "\n",
      "Matrix 17:\n",
      "[[ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0.5+0.j   0. +0.j   0. -0.5j]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. -0.5j  0. +0.j  -0.5+0.j ]]\n",
      "\n",
      "Matrix 18:\n",
      "[[ 0.25+0.j   -0.25+0.j    0.  -0.25j  0.  +0.25j]\n",
      " [-0.25+0.j    0.25+0.j    0.  +0.25j  0.  -0.25j]\n",
      " [ 0.  -0.25j  0.  +0.25j -0.25+0.j    0.25+0.j  ]\n",
      " [ 0.  +0.25j  0.  -0.25j  0.25+0.j   -0.25+0.j  ]]\n",
      "\n",
      "Matrix 19:\n",
      "[[ 0.25+0.j -0.25+0.j  0.25+0.j -0.25+0.j]\n",
      " [-0.25+0.j  0.25+0.j -0.25+0.j  0.25+0.j]\n",
      " [ 0.25+0.j -0.25+0.j  0.25+0.j -0.25+0.j]\n",
      " [-0.25+0.j  0.25+0.j -0.25+0.j  0.25+0.j]]\n",
      "\n",
      "Matrix 20:\n",
      "[[0. +0.j 0. +0.j 0. +0.j 0. +0.j]\n",
      " [0. +0.j 0.5+0.j 0. +0.j 0.5+0.j]\n",
      " [0. +0.j 0. +0.j 0. +0.j 0. +0.j]\n",
      " [0. +0.j 0.5+0.j 0. +0.j 0.5+0.j]]\n",
      "\n",
      "Matrix 21:\n",
      "[[ 0.25+0.j    0.  -0.25j  0.25+0.j    0.  -0.25j]\n",
      " [ 0.  -0.25j -0.25+0.j    0.  -0.25j -0.25+0.j  ]\n",
      " [ 0.25+0.j    0.  -0.25j  0.25+0.j    0.  -0.25j]\n",
      " [ 0.  -0.25j -0.25+0.j    0.  -0.25j -0.25+0.j  ]]\n",
      "\n",
      "Matrix 22:\n",
      "[[0.25+0.j 0.25+0.j 0.25+0.j 0.25+0.j]\n",
      " [0.25+0.j 0.25+0.j 0.25+0.j 0.25+0.j]\n",
      " [0.25+0.j 0.25+0.j 0.25+0.j 0.25+0.j]\n",
      " [0.25+0.j 0.25+0.j 0.25+0.j 0.25+0.j]]\n",
      "\n",
      "Matrix 23:\n",
      "[[ 0.25+0.j    0.  +0.25j  0.25+0.j    0.  +0.25j]\n",
      " [ 0.  +0.25j -0.25+0.j    0.  +0.25j -0.25+0.j  ]\n",
      " [ 0.25+0.j    0.  +0.25j  0.25+0.j    0.  +0.25j]\n",
      " [ 0.  +0.25j -0.25+0.j    0.  +0.25j -0.25+0.j  ]]\n",
      "\n",
      "Matrix 24:\n",
      "[[0.5+0.j 0. +0.j 0.5+0.j 0. +0.j]\n",
      " [0. +0.j 0. +0.j 0. +0.j 0. +0.j]\n",
      " [0.5+0.j 0. +0.j 0.5+0.j 0. +0.j]\n",
      " [0. +0.j 0. +0.j 0. +0.j 0. +0.j]]\n",
      "\n",
      "Matrix 25:\n",
      "[[0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      " [0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      " [0.+0.j 0.+0.j 1.+0.j 0.+0.j]\n",
      " [0.+0.j 0.+0.j 0.+0.j 0.+0.j]]\n",
      "\n",
      "Matrix 26:\n",
      "[[ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0.5+0.j   0. +0.5j]\n",
      " [ 0. +0.j   0. +0.j   0. +0.5j -0.5+0.j ]]\n",
      "\n",
      "Matrix 27:\n",
      "[[0. +0.j 0. +0.j 0. +0.j 0. +0.j]\n",
      " [0. +0.j 0. +0.j 0. +0.j 0. +0.j]\n",
      " [0. +0.j 0. +0.j 0.5+0.j 0.5+0.j]\n",
      " [0. +0.j 0. +0.j 0.5+0.j 0.5+0.j]]\n",
      "\n",
      "Matrix 28:\n",
      "[[ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0.5+0.j   0. -0.5j]\n",
      " [ 0. +0.j   0. +0.j   0. -0.5j -0.5+0.j ]]\n",
      "\n",
      "Matrix 29:\n",
      "[[0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      " [0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      " [0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      " [0.+0.j 0.+0.j 0.+0.j 1.+0.j]]\n",
      "\n",
      "Matrix 30:\n",
      "[[ 0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j  0.5+0.j -0.5+0.j]\n",
      " [ 0. +0.j  0. +0.j -0.5+0.j  0.5+0.j]]\n",
      "\n",
      "Matrix 31:\n",
      "[[ 0.25+0.j -0.25+0.j -0.25+0.j  0.25+0.j]\n",
      " [-0.25+0.j  0.25+0.j  0.25+0.j -0.25+0.j]\n",
      " [-0.25+0.j  0.25+0.j  0.25+0.j -0.25+0.j]\n",
      " [ 0.25+0.j -0.25+0.j -0.25+0.j  0.25+0.j]]\n",
      "\n",
      "Matrix 32:\n",
      "[[ 0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j  0.5+0.j  0. +0.j -0.5+0.j]\n",
      " [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n",
      " [ 0. +0.j -0.5+0.j  0. +0.j  0.5+0.j]]\n",
      "\n",
      "Matrix 33:\n",
      "[[ 0.25+0.j    0.  -0.25j -0.25+0.j    0.  +0.25j]\n",
      " [ 0.  -0.25j -0.25+0.j    0.  +0.25j  0.25+0.j  ]\n",
      " [-0.25+0.j    0.  +0.25j  0.25+0.j    0.  -0.25j]\n",
      " [ 0.  +0.25j  0.25+0.j    0.  -0.25j -0.25+0.j  ]]\n",
      "\n",
      "Matrix 34:\n",
      "[[ 0.25+0.j  0.25+0.j -0.25+0.j -0.25+0.j]\n",
      " [ 0.25+0.j  0.25+0.j -0.25+0.j -0.25+0.j]\n",
      " [-0.25+0.j -0.25+0.j  0.25+0.j  0.25+0.j]\n",
      " [-0.25+0.j -0.25+0.j  0.25+0.j  0.25+0.j]]\n",
      "\n",
      "Matrix 35:\n",
      "[[ 0.25+0.j    0.  +0.25j -0.25+0.j    0.  -0.25j]\n",
      " [ 0.  +0.25j -0.25+0.j    0.  -0.25j  0.25+0.j  ]\n",
      " [-0.25+0.j    0.  -0.25j  0.25+0.j    0.  +0.25j]\n",
      " [ 0.  -0.25j  0.25+0.j    0.  +0.25j -0.25+0.j  ]]\n",
      "\n",
      "Matrix 36:\n",
      "[[ 0.5+0.j  0. +0.j -0.5+0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n",
      " [-0.5+0.j  0. +0.j  0.5+0.j  0. +0.j]\n",
      " [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@Saumya\n",
    "\n",
    "# Define six 2x1 matrices\n",
    "matrices = [\n",
    "    np.array([[1], [0]]),                                # Ket H \n",
    "    np.array([[1/np.sqrt(2)], [1j/np.sqrt(2)]]),         # Ket R \n",
    "    np.array([[1/np.sqrt(2)], [-1j/np.sqrt(2)]]),        # Ket L \n",
    "    np.array([[1/np.sqrt(2)], [1/np.sqrt(2)]]),          # Ket D \n",
    "    np.array([[0], [1]]),                                # Ket V\n",
    "    np.array([[1/np.sqrt(2)], [-1/np.sqrt(2)]])          # Ket A \n",
    "]\n",
    "\n",
    "labels = ['H', 'R', 'L', 'D', 'V', 'A']\n",
    "seq = np.array([0, 1, 3, 2, 4, 5])\n",
    "revseq = np.array([5, 4, 2, 3, 1, 0])\n",
    "\n",
    "# Pre-allocate an array to store 36 projection matrices of size 4x4\n",
    "opers = np.zeros((36, 4, 4), dtype=complex)\n",
    "\n",
    "s = 0  # Index to save projection matrices\n",
    "for i in range(0, 6, 2):\n",
    "    for j in range(6):\n",
    "        # Compute the projection matrix\n",
    "        projection = np.dot(\n",
    "            np.kron(matrices[i], matrices[seq[j]]),\n",
    "            np.transpose(np.kron(matrices[i], matrices[seq[j]]))\n",
    "        )\n",
    "        opers[s] = projection  # Save the projection matrix in the array\n",
    "        print(f\"Projection number {s + 1} (|{labels[i]}⟩⟨{labels[seq[j]]}|):\")\n",
    "        print(projection)\n",
    "        s += 1\n",
    "\n",
    "    i += 1\n",
    "    for k in range(6):\n",
    "        # Compute the projection matrix\n",
    "        projection = np.dot(\n",
    "            np.kron(matrices[i], matrices[revseq[k]]),\n",
    "            np.transpose(np.kron(matrices[i], matrices[revseq[k]]))\n",
    "        )\n",
    "        opers[s] = projection  # Save the projection matrix in the array\n",
    "        print(f\"Projection number {s + 1} (|{labels[i]}⟩⟨{labels[revseq[k]]}|):\")\n",
    "        print(projection)\n",
    "        s += 1\n",
    "\n",
    "# Verify the saved matrices\n",
    "print(\"\\nSaved projection matrices in 'opers':\")\n",
    "for idx, op in enumerate(opers, start=1):\n",
    "    print(f\"Matrix {idx}:\\n{op}\\n\")\n",
    "    #print(opers[1,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurement Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor shape: (36, 4, 4)\n",
      "total_sum: 1429\n",
      "NumPy Array: [[0.48005598 0.24352694 0.21413576 0.30230931 0.0069979  0.28551435\n",
      "  0.48075577 0.28971309 0.2463261  0.04268719 0.27641707 0.22253324\n",
      "  0.2673198  0.20153954 0.46606018 0.21203639 0.21623513 0.03988803\n",
      "  0.23792862 0.27851645 0.45346396 0.25822253 0.04688593 0.21763471\n",
      "  0.00559832 0.23303009 0.2393282  0.21203639 0.5073478  0.22323303\n",
      "  0.36319104 0.02309307 0.10706788 0.12736179 0.39958013 0.31280616]]\n",
      "Shape: (1, 36)\n"
     ]
    }
   ],
   "source": [
    "m_ops = opers\n",
    "print(\"Tensor shape:\", m_ops.shape)\n",
    "data_list = [686,348,306,432,10,408,687,414,352,61,395,318,382,288,666,303,309,57,340,398,648,369,67,311,8,333,342,303,725,319,519,33,153,182,571,447]\n",
    "total_sum = 1429 #sum(data_list)\n",
    "normalized_data= [y/ total_sum for y in data_list]\n",
    "#data= torch.tensor(data_list).reshape(1, -1)\n",
    "data = np.array(normalized_data).reshape(1, -1)\n",
    "tot_data=data\n",
    "tot_ops=opers\n",
    "# Print the NumPy array and its shape\n",
    "print(\"total_sum:\",total_sum)\n",
    "print(\"NumPy Array:\", data)\n",
    "print(\"Shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change of dimension from 4x4 to 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complex128\n",
      "Expanded Opers Shape (36, 32, 32)\n",
      "[[ 0.5+0.j   0. +0.5j  0. +0.j  ...  0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.5j -0.5+0.j   0. +0.j  ...  0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j  ...  0. +0.j   0. +0.j   0. +0.j ]\n",
      " ...\n",
      " [ 0. +0.j   0. +0.j   0. +0.j  ...  0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j  ...  0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j  ...  0. +0.j   0. +0.j   0. +0.j ]]\n"
     ]
    }
   ],
   "source": [
    "expanded_opers_real = np.zeros((tot_ops.shape[0], 32, 32))\n",
    "expanded_opers_imag = np.zeros((tot_ops.shape[0], 32, 32))\n",
    "\n",
    "for i in range(tot_ops.shape[0]):\n",
    "    expanded_opers_real[i, :4, :4] = tot_ops[i].real\n",
    "    expanded_opers_imag[i, :4, :4] = tot_ops[i].imag\n",
    "    # Combine real and imaginary parts into a single complex array\n",
    "expanded_opers = expanded_opers_real + 1j * expanded_opers_imag\n",
    "\n",
    "# Verify the shape and type\n",
    "print(expanded_opers.dtype)  # Should be complex\n",
    "\n",
    "print(\"Expanded Opers Shape\",expanded_opers.shape) \n",
    "print(expanded_opers[1])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coverting to TensorFlow Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 36, 32, 32)\n",
      "ops_tf shape: (1, 36, 32, 32) <dtype: 'complex128'>\n",
      "Shape of A is (1, 32, 32, 72)\n",
      "the first real part of the first operator in A tf.Tensor(\n",
      "[[[ 1.    0.5   0.5  ...  0.25  0.25  0.5 ]\n",
      "  [ 0.    0.    0.5  ...  0.25  0.    0.  ]\n",
      "  [ 0.    0.    0.   ... -0.25 -0.25 -0.5 ]\n",
      "  ...\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]]\n",
      "\n",
      " [[ 0.    0.    0.5  ...  0.25  0.    0.  ]\n",
      "  [ 0.   -0.5   0.5  ...  0.25 -0.25  0.  ]\n",
      "  [ 0.    0.    0.   ... -0.25  0.    0.  ]\n",
      "  ...\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]]\n",
      "\n",
      " [[ 0.    0.    0.   ... -0.25 -0.25 -0.5 ]\n",
      "  [ 0.    0.    0.   ... -0.25  0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.25  0.25  0.5 ]\n",
      "  ...\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  ...\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]]\n",
      "\n",
      " [[ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  ...\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]]\n",
      "\n",
      " [[ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  ...\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]]], shape=(32, 32, 36), dtype=float64)\n",
      "Data type of 'opers': complex128\n",
      "Trace of the matrix: (1.0000005+0j)\n",
      "[[1.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      " [0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      " [0.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
      " [0.+0.j 0.+0.j 0.+0.j 0.+0.j]]\n",
      "tf.Tensor(\n",
      "[[[ 1.    0.5   0.5  ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.5  ...  0.    0.25  0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  ...\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]]\n",
      "\n",
      " [[ 0.    0.    0.5  ...  0.    0.25  0.  ]\n",
      "  [ 0.   -0.5   0.5  ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.   -0.25  0.  ]\n",
      "  ...\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]]\n",
      "\n",
      " [[ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.   -0.25  0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  ...\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  ...\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]]\n",
      "\n",
      " [[ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  ...\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]]\n",
      "\n",
      " [[ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  ...\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]\n",
      "  [ 0.    0.    0.   ...  0.    0.    0.  ]]], shape=(32, 32, 72), dtype=float64)\n",
      "The trace of rho*P_HH is: (0.47268+0j)\n",
      "[[ 0.5+0.j   0. +0.5j  0. +0.j   0. +0.j ]\n",
      " [ 0. +0.5j -0.5+0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]\n",
      " [ 0. +0.j   0. +0.j   0. +0.j   0. +0.j ]]\n",
      "The trace of rho*P_HR is: (0.0418517+0j)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-25 03:05:37.965606: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-12-25 03:05:37.966194: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-12-25 03:05:37.966366: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-12-25 03:05:37.966516: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-12-25 03:05:37.966672: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-12-25 03:05:37.966813: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-12-25 03:05:37.966948: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-12-25 03:05:37.967091: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-12-25 03:05:37.967221: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-12-25 03:05:37.967251: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-12-25 03:05:37.968115: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ops_tf = tf.convert_to_tensor([expanded_opers]) # convert the numpy arrays to complex TensorFlow tensors\n",
    "print(ops_tf.shape)\n",
    "#print(ops_tf[0,0])\n",
    "print(\"ops_tf shape:\", ops_tf.shape,ops_tf.dtype)\n",
    "A = convert_to_real_ops(ops_tf) # convert the complex-valued numpy matrices to real-valued TensorFlow tensors\n",
    "print(\"Shape of A is\",A.shape)\n",
    "print(\"the first real part of the first operator in A\",A[0, :, :, :36])\n",
    "rho_tf = np.array([[0.47268, -0.046671+0.0359951j, -0.0350205+0.0123738j, 0.0532487+0.387632j],\n",
    "                       [-0.046671-0.0359951j, 0.0418517, 0.0285187+0.0148695j, 0.0259252-0.0386607j],\n",
    "                       [-0.0350205-0.0123738j, 0.0285187-0.0148695j, 0.0268008, 0.000990322-0.0147513j],\n",
    "                       [0.0532487-0.387632j, 0.0259252+0.0386607j, 0.000990322+0.0147513j, 0.458668]])\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the trace\n",
    "print(\"Data type of 'opers':\", opers.dtype)\n",
    "trace_rho = np.trace(rho_tf)\n",
    "print(\"Trace of the matrix:\", trace_rho)\n",
    "# Calculate the trace\n",
    "#print(np.dot(rho_tf,opers[0]))\n",
    "trace0 = np.trace(np.dot(rho_tf,opers[0]))\n",
    "trace1 = np.trace(np.dot(rho_tf,opers[4]))\n",
    "print(opers[0])\n",
    "print(A[0])\n",
    "print(\"The trace of rho*P_HH is:\", trace0)#/data[0,0])\n",
    "print(opers[1])\n",
    "print(\"The trace of rho*P_HR is:\", trace1)#/data[0,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Rho_tf to 32x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4) (32, 32) [[ 0.47268  +0.j        -0.046671 +0.0359951j -0.0350205+0.0123738j ...\n",
      "   0.       +0.j         0.       +0.j         0.       +0.j       ]\n",
      " [-0.046671 -0.0359951j  0.0418517+0.j         0.0285187+0.0148695j ...\n",
      "   0.       +0.j         0.       +0.j         0.       +0.j       ]\n",
      " [-0.0350205-0.0123738j  0.0285187-0.0148695j  0.0268008+0.j        ...\n",
      "   0.       +0.j         0.       +0.j         0.       +0.j       ]\n",
      " ...\n",
      " [ 0.       +0.j         0.       +0.j         0.       +0.j        ...\n",
      "   0.       +0.j         0.       +0.j         0.       +0.j       ]\n",
      " [ 0.       +0.j         0.       +0.j         0.       +0.j        ...\n",
      "   0.       +0.j         0.       +0.j         0.       +0.j       ]\n",
      " [ 0.       +0.j         0.       +0.j         0.       +0.j        ...\n",
      "   0.       +0.j         0.       +0.j         0.       +0.j       ]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a 32x32 complex matrix with zeros\n",
    "rho_tf32 = np.zeros((32, 32), dtype=np.complex128)\n",
    "\n",
    "# Assign the 4x4 complex matrix to the top-left corner\n",
    "rho_tf32[:4, :4] = rho_tf\n",
    "\n",
    "# Print the resulting 32x32 matrix\n",
    "print(rho_tf.shape,rho_tf32.shape,rho_tf32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the CGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "Dtype: <dtype: 'float64'>\n",
      "Tensor shape: (1, 36)\n"
     ]
    }
   ],
   "source": [
    "hilbert_size=32\n",
    "#x=tot_data\n",
    "x= tf.convert_to_tensor(tot_data.reshape(1, -1))\n",
    "x= tf.cast(x, dtype=tf.float64)\n",
    "print(type(x)) \n",
    "print(f\"Dtype: {x.dtype}\")\n",
    "print(\"Tensor shape:\", x.shape)\n",
    "num_measurements = x.shape[-1]\n",
    "#tf.print(\"Dynamic num_measurementss:\", tf.shape(x)[-1])\n",
    "\n",
    "generator = Generator(hilbert_size, num_measurements, noise=0.0) # Specify the number of measurement settings and Gaussian noise\n",
    "discriminator = Discriminator(hilbert_size, num_measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density Matrix Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "density_layer_idx = None\n",
    "\n",
    "for i, layer in enumerate(generator.layers):\n",
    "    if \"density_matrix\" in layer._name:\n",
    "        density_layer_idx = i\n",
    "       # breakgetcwd\n",
    "\n",
    "print(density_layer_idx)\n",
    "model_dm = tf.keras.Model(inputs=generator.input, outputs=generator.layers[density_layer_idx].output)\n",
    "\n",
    "@dataclass\n",
    "class LossHistory:\n",
    "    \"\"\"Class for keeping track of loss\"\"\"\n",
    "    generator: list\n",
    "    discriminator: list\n",
    "    l1: list\n",
    "\n",
    "loss = LossHistory([], [], [])\n",
    "fidelities = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.000075\n",
    "#lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(initial_learning_rate)\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(initial_learning_rate,\n",
    "                                                     decay_steps=100,\n",
    "                                                     decay_rate=0.96,\n",
    "                                                     staircase=False)  \n",
    "\n",
    "lam =100.\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(lr_schedule, 0.5, 0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(lr_schedule, 0.5, 0.5)\n",
    "\n",
    "max_iterations=5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fidelity 0.3996852368103471 | Gen loss 0.6940598060460816 | L1 loss 0.11553533685021367 | Disc loss 1.3844192427952018:   3%|▎         | 145/5000 [00:35<19:43,  4.10it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_69593/2680822074.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mdensity_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_dm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_fidelity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdensity_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho_tf32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_69593/2680822074.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(A, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m     discriminator_gradients = disc_tape.gradient(\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mdisc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     )\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/qstgan/venv37/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/qstgan/venv37/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/qstgan/venv37/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m def _gradient_function(op_name, attr_tuple, num_inputs, inputs, outputs,\n\u001b[0m\u001b[1;32m    128\u001b[0m                        out_grads, skip_input_indices, forward_pass_name_scope):\n\u001b[1;32m    129\u001b[0m   \"\"\"Calls the gradient function of the op.\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_step(A, x):\n",
    "    \"\"\"Takes one step of training for the full A matrix representing the\n",
    "    measurement operators and data x.\n",
    "\n",
    "    Note that the `generator`, `discriminator`, `generator_optimizer` and the\n",
    "    `discriminator_optimizer` has to be defined before calling this function.\n",
    "\n",
    "    Args:\n",
    "        A (tf.Tensor): A tensor of shape (m, hilbert_size, hilbert_size, n x 2)\n",
    "                       where m=1 for a single reconstruction, and n represents\n",
    "                       the number of measured operators. We split the complex\n",
    "                       operators as real and imaginary in the last axis. The \n",
    "                       helper function `convert_to_real_ops` can be used to\n",
    "                       generate the matrix A with a set of complex operators\n",
    "                       given by `ops` with shape (1, n, hilbert_size, hilbert_size)\n",
    "                       by calling `A = convert_to_real_ops(ops)`.\n",
    "\n",
    "        x (tf.Tensor): A tensor of shape (m, n) with m=1 for a single\n",
    "                       reconstruction and `n` representing the number of\n",
    "                       measurements. \n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        gen_output = generator([A, x], training=True)\n",
    "        \n",
    "        \n",
    "        disc_real_output = discriminator([A, x, x], training=True)\n",
    "        disc_generated_output = discriminator([A, x, gen_output], training=True)\n",
    "\n",
    "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(\n",
    "            disc_generated_output, gen_output, x, lam=lam\n",
    "        )\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(\n",
    "        gen_total_loss, generator.trainable_variables\n",
    "    )\n",
    "    discriminator_gradients = disc_tape.gradient(\n",
    "        disc_loss, discriminator.trainable_variables\n",
    "    )\n",
    "\n",
    "    generator_optimizer.apply_gradients(\n",
    "        zip(generator_gradients, generator.trainable_variables)\n",
    "    )\n",
    "    discriminator_optimizer.apply_gradients(\n",
    "        zip(discriminator_gradients, discriminator.trainable_variables)\n",
    "    )\n",
    "\n",
    "    loss.generator.append(gen_gan_loss)\n",
    "    loss.l1.append(gen_l1_loss)\n",
    "    loss.discriminator.append(disc_loss)\n",
    "\n",
    "\n",
    "pbar = tqdm(range(max_iterations))\n",
    "\n",
    "#rho_tf = np.loadtxt(\"/home/aq/Downloads/DensityMatrix.csv\", delimiter=\",\")\n",
    "#print(rho_tf)\n",
    "\n",
    "# Use the density matrix from MLE to compare\n",
    "\n",
    "\n",
    "for i in pbar:\n",
    "    train_step(A, x)\n",
    "    density_matrix = model_dm([A, x])\n",
    "    f = tf_fidelity(density_matrix, rho_tf32)[-1]\n",
    "    fidelities.append(f)\n",
    "    pbar.set_description(\"Fidelity {} | Gen loss {} | L1 loss {} | Disc loss {}\".format(f, loss.generator[-1], loss.l1[-1], loss.discriminator[-1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = np.arange(len(fidelities))\n",
    "plt.plot(iterations, fidelities, color=\"red\", label=\"QST-CGAN\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Fidelity\")\n",
    "plt.ylim(0, 1.1)\n",
    "plt.grid(which='minor', alpha=0.2)\n",
    "plt.grid(which='major', alpha=0.2)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
